{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/AI-Innovation-2024/blob/main/NLP/4-4-Using_chained_calls_for_o1_structured_outputs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgGm-vZyCOCp"
      },
      "source": [
        "# Using chained calls for reasoning structured outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQRMG_8ECOCr"
      },
      "source": [
        "The initially released versions (September 2024) of [o1](https://openai.com/index/introducing-openai-o1-preview/) reasoning models have advanced capabilities but do not have [structured outputs](https://platform.openai.com/docs/guides/structured-outputs/examples) support.\n",
        "\n",
        "This means that requests with o1 don't have reliable type-safety and rely on the prompt itself to return a useful JSON.\n",
        "\n",
        "In this guide, we'll explore two methods to prompt o1 models, specifically `o1-preview`, to return a valid JSON format when using the OpenAI API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYFB3Lk_COCs"
      },
      "source": [
        "# Prompting\n",
        "\n",
        "The simplest way to return a JSON response using `o1-preview` is to explicitly prompt it.\n",
        "\n",
        "Let's run through an example of:\n",
        "- Fetching a wikipedia page of companies\n",
        "- Determining which could benefit the most from AI capabilities\n",
        "- Returning them in a JSON format, which could then be ingested by other systems"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai devtools"
      ],
      "metadata": {
        "id": "iNCOcyCMCSX7",
        "outputId": "0f2bc45d-5a5e-4bcf-abf5-b78b3a52ab2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.51.0)\n",
            "Collecting devtools\n",
            "  Downloading devtools-0.12.2-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Collecting asttokens<3.0.0,>=2.0.0 (from devtools)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting executing>=1.1.1 (from devtools)\n",
            "  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: pygments>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from devtools) (2.18.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens<3.0.0,>=2.0.0->devtools) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading devtools-0.12.2-py3-none-any.whl (19 kB)\n",
            "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: executing, asttokens, devtools\n",
            "Successfully installed asttokens-2.4.1 devtools-0.12.2 executing-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "go8DjaBCCO_Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oo3CYkOeCOCs",
        "outputId": "c58ef660-d7ca-409f-d1ad-02e5c723297d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"companies\": [\n",
            "        {\n",
            "            \"company_name\": \"Walmart\",\n",
            "            \"page_link\": \"https://en.wikipedia.org/wiki/Walmart\",\n",
            "            \"reason\": \"As the largest retailer, Walmart can benefit from AI technology to optimize its supply chain, improve inventory management, enhance customer experience with personalized recommendations, and streamline operations.\"\n",
            "        },\n",
            "        {\n",
            "            \"company_name\": \"UnitedHealth Group\",\n",
            "            \"page_link\": \"https://en.wikipedia.org/wiki/UnitedHealth_Group\",\n",
            "            \"reason\": \"UnitedHealth Group can leverage AI for predictive analytics in patient care, improve diagnostics, personalize treatment plans, and optimize administrative processes in healthcare management.\"\n",
            "        },\n",
            "        {\n",
            "            \"company_name\": \"JPMorgan Chase\",\n",
            "            \"page_link\": \"https://en.wikipedia.org/wiki/JPMorgan_Chase\",\n",
            "            \"reason\": \"As a leading financial institution, JPMorgan Chase can use AI for fraud detection, risk management, algorithmic trading, and enhancing customer service through personalized banking solutions.\"\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "def fetch_html(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.text\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "url = \"https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue\"\n",
        "html_content = fetch_html(url)\n",
        "\n",
        "json_format = \"\"\"\n",
        "{\n",
        "    companies: [\n",
        "        {\n",
        "            \\\"company_name\\\": \\\"OpenAI\\\",\n",
        "            \\\"page_link\\\": \\\"https://en.wikipedia.org/wiki/OpenAI\\\",\n",
        "            \\\"reason\\\": \\\"OpenAI would benefit because they are an AI company...\\\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "o1_response = client.chat.completions.create(\n",
        "    model=\"o1-preview\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"\n",
        "You are a business analyst designed to understand how AI technology could be used across large corporations.\n",
        "\n",
        "- Read the following html and return which companies would benefit from using AI technology: {html_content}.\n",
        "- Rank these propects by opportunity by comparing them and show me the top 3. Return only as a JSON with the following format: {json_format}\"\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(o1_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4KQwjFSCOCu"
      },
      "source": [
        "Note that the response is already quite good - it returns the JSON with the appropriate responses. However, it runs into the same pitfalls as existing use-cases of prompt-only JSON inference:\n",
        "- You must manually process this JSON into your type-safe structure\n",
        "- Model refusals are not [explicitly returned from the API as a separate structure](https://platform.openai.com/docs/guides/structured-outputs/refusals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrbpoLd0COCu"
      },
      "source": [
        "# Structured Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzpL3bSRCOCv"
      },
      "source": [
        "Let's now do this with [structured outputs](https://platform.openai.com/docs/guides/structured-outputs). To enable this functionality, we’ll link the `o1-preview` response with a follow-up request to `gpt-4o-mini`, which can effectively process the data returned from the initial o1-preview response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j5YNV5j1COCv",
        "outputId": "c897c9f4-6c57-497b-bdb0-e498c7154ea8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CompaniesData(\n",
            "    companies=[\n",
            "        CompanyData(\n",
            "            company_name='Walmart',\n",
            "            page_link='/wiki/Walmart',\n",
            "            reason=(\n",
            "                \"As the world's largest retailer, Walmart can significantly benefit from AI technology to optimize its\"\n",
            "                ' vast supply chain, improve demand forecasting, enhance inventory management, and personalize custome'\n",
            "                'r experiences. Implementing AI can lead to cost reductions, increased efficiency, and a competitive e'\n",
            "                'dge in the retail market.'\n",
            "            ),\n",
            "        ),\n",
            "        CompanyData(\n",
            "            company_name='UnitedHealth Group',\n",
            "            page_link='/wiki/UnitedHealth_Group',\n",
            "            reason=(\n",
            "                'As a leading healthcare company, UnitedHealth Group can leverage AI to enhance patient care through p'\n",
            "                'redictive analytics, automate administrative tasks, detect fraud, and personalize health plans. AI ca'\n",
            "                'n help process large volumes of medical data to improve diagnostic accuracy and treatment outcomes.'\n",
            "            ),\n",
            "        ),\n",
            "        CompanyData(\n",
            "            company_name='ExxonMobil',\n",
            "            page_link='/wiki/ExxonMobil',\n",
            "            reason=(\n",
            "                'Operating in the petroleum industry, ExxonMobil can utilize AI for predictive maintenance of equipmen'\n",
            "                't, optimize exploration and drilling processes, improve energy efficiency, and analyze large datasets'\n",
            "                ' for better decision-making. AI can lead to reduced operational costs and enhanced safety measures in'\n",
            "                ' their operations.'\n",
            "            ),\n",
            "        ),\n",
            "    ],\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel\n",
        "from devtools import pprint\n",
        "\n",
        "class CompanyData(BaseModel):\n",
        "    company_name: str\n",
        "    page_link: str\n",
        "    reason: str\n",
        "\n",
        "class CompaniesData(BaseModel):\n",
        "    companies: list[CompanyData]\n",
        "\n",
        "o1_response = client.chat.completions.create(\n",
        "    model=\"o1-preview\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"\n",
        "You are a business analyst designed to understand how AI technology could be used across large corporations.\n",
        "\n",
        "- Read the following html and return which companies would benefit from using AI technology: {html_content}.\n",
        "- Rank these propects by opportunity by comparing them and show me the top 3. Return each with {CompanyData.__fields__.keys()}\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "o1_response_content = o1_response.choices[0].message.content\n",
        "\n",
        "response = client.beta.chat.completions.parse(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"\n",
        "Given the following data, format it with the given response format: {o1_response_content}\n",
        "\"\"\"\n",
        "        }\n",
        "    ],\n",
        "    response_format=CompaniesData,\n",
        ")\n",
        "\n",
        "pprint(response.choices[0].message.parsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UtuvKM-COCv"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "Structured outputs allow your code to have reliable type-safety and simpler prompting. In addition, it allows you to re-use your object schemas for easier integration into your existing workflows.\n",
        "\n",
        "The o1 class of models currently doesn't have structured outputs support, but we can re-use existing structured outputs functionality from `gpt-4o-mini` by chaining two requests together. This flow currently requires two calls, but the second `gpt-4o-mini` call cost should be minimal compared to the `o1-preview`/`o1-mini` calls."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}