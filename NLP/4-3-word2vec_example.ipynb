{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/AI-Innovation-2024/blob/main/NLP/4-3-word2vec_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "532ddde6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "532ddde6",
        "outputId": "c7bac324-9dfe-4f3b-98db-fd5603e48d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary library (if not already installed)\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "de91bd73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de91bd73",
        "outputId": "127b7a8a-d777-4676-ec7a-0c9cf8a54d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "# nltk 데이터 다운로드 (첫 실행 시에만 필요)\n",
        "nltk.download('punkt')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f021efd8",
      "metadata": {
        "id": "f021efd8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 예제 문장 데이터\n",
        "sentences = [\n",
        "    \"The quick brown fox jumps over the lazy dog\",\n",
        "    \"I love natural language processing and machine learning\",\n",
        "    \"Word2Vec is a method to learn word embeddings\",\n",
        "    \"Deep learning models often require a lot of data to perform well\",\n",
        "    \"Gensim is a great library for natural language processing\"\n",
        "]\n",
        "\n",
        "# 문장들을 토큰화\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b6656fee",
      "metadata": {
        "id": "b6656fee"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Word2Vec 모델 생성 및 학습\n",
        "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, sg=0)  # sg=0: CBOW 모델, sg=1: Skip-gram 모델\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "497a961c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "497a961c",
        "outputId": "7b3f39f4-ae8f-489c-ad99-25f7313dae7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for 'word2vec': [ 1.3327437e-03  6.5392954e-03  9.9839829e-03  9.0612099e-03\n",
            " -8.0165816e-03  6.4898157e-03 -5.7141553e-03 -9.6975203e-04\n",
            "  4.8343191e-04  6.5795328e-03  4.4718366e-03  4.6052895e-03\n",
            "  9.4817961e-03  3.8256825e-04 -6.0387240e-03 -6.3282927e-03\n",
            "  6.4314557e-03 -5.2422909e-03 -2.8506136e-03  4.0731020e-03\n",
            " -2.2925166e-03 -6.0254615e-03 -2.3240175e-03  1.2068190e-03\n",
            "  2.1831139e-03  6.0827993e-03 -5.2128206e-03  3.0776935e-03\n",
            "  7.2411140e-03  2.1951853e-03  5.3989454e-03 -4.8452769e-03\n",
            "  6.1542820e-03 -7.6011396e-03  3.4942867e-03 -9.3233129e-03\n",
            " -2.6039402e-03 -9.0756686e-03 -1.5863272e-03 -5.3644320e-03\n",
            " -3.9441618e-03  1.1517477e-03  2.8009464e-03 -1.5281484e-03\n",
            " -8.1679830e-03 -5.9202653e-03  8.2134194e-04 -3.9464738e-03\n",
            " -9.4292071e-03 -7.7411387e-04  6.6336337e-03  5.9791291e-03\n",
            " -9.9167544e-03  3.1199649e-03 -5.9851413e-03 -9.1812322e-03\n",
            "  1.7193661e-04 -3.6757113e-04 -6.9717309e-03 -6.2777917e-03\n",
            " -2.4257582e-03  7.0969719e-03 -7.5453324e-03  7.6990072e-03\n",
            " -4.7615601e-04  1.0938010e-03  9.4824648e-03  4.7280099e-03\n",
            " -3.5745706e-03  3.7378320e-03  3.5194873e-03  6.3353898e-03\n",
            "  7.1484697e-05 -4.4241608e-03  1.3182868e-03 -5.4147243e-03\n",
            "  1.4117184e-03  4.9270913e-03  5.1545375e-03  9.1809398e-03\n",
            " -7.5102835e-03 -5.4040286e-03  6.4676912e-03  1.3576420e-03\n",
            " -6.6095339e-03  8.8543701e-04  2.6765657e-03 -2.5282062e-03\n",
            " -4.9593360e-03  5.0068819e-03  9.6210111e-03 -7.3658973e-03\n",
            " -1.1462791e-04 -2.5647243e-03 -6.3644042e-03 -1.3795338e-03\n",
            " -5.2478239e-03  9.0592634e-03 -5.7884408e-03  3.6837477e-03]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 단어 'word2vec'의 벡터를 확인\n",
        "word_vector = model.wv['word2vec']\n",
        "print(f\"Vector for 'word2vec': {word_vector}\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1328566c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1328566c",
        "outputId": "690fa86e-733f-4529-99bd-6be60abf8592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between 'word2vec' and 'learning': -0.1516\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 단어 간 유사도 확인\n",
        "similarity = model.wv.similarity('word2vec', 'learning')\n",
        "print(f\"Similarity between 'word2vec' and 'learning': {similarity:.4f}\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a695216b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a695216b",
        "outputId": "2e0c1751-a428-4bae-ce77-642765c11af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words most similar to 'natural': [('machine', 0.304378479719162), ('and', 0.17776663601398468), ('perform', 0.16441375017166138)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 'natural'과 가장 유사한 단어 3개 찾기\n",
        "similar_words = model.wv.most_similar('natural', topn=3)\n",
        "print(f\"Words most similar to 'natural': {similar_words}\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "14f4c3b4",
      "metadata": {
        "id": "14f4c3b4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 모델 저장\n",
        "model.save(\"word2vec_example.model\")\n",
        "\n",
        "# 모델 불러오기\n",
        "loaded_model = Word2Vec.load(\"word2vec_example.model\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 불러오기\n",
        "loaded_model = Word2Vec.load(\"word2vec_example.model\")\n",
        "\n",
        "# 단어 벡터 확인\n",
        "word_vector = loaded_model.wv['word2vec']\n",
        "print(f\"Vector for 'word2vec': {word_vector}\")\n",
        "\n",
        "# 단어 간 유사도 확인\n",
        "similarity = loaded_model.wv.similarity('word2vec', 'learning')\n",
        "print(f\"Similarity between 'word2vec' and 'learning': {similarity:.4f}\")\n",
        "\n",
        "# 유사한 단어 찾기\n",
        "similar_words = loaded_model.wv.most_similar('natural', topn=3)\n",
        "print(f\"Words most similar to 'natural': {similar_words}\")\n",
        "\n",
        "# 단어 벡터 간 산술 연산 예제\n",
        "# 'king' - 'man' + 'woman'과 가장 유사한 단어 찾기 (예제에서는 다른 단어로 활용 가능)\n",
        "try:\n",
        "    result = loaded_model.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
        "    print(f\"Result of 'king' - 'man' + 'woman': {result}\")\n",
        "except KeyError as e:\n",
        "    print(f\"Word not in vocabulary: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOMjQff4bNjO",
        "outputId": "2dc49b6a-ab02-47a7-d7a5-fa1f1aae7c2e"
      },
      "id": "AOMjQff4bNjO",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for 'word2vec': [ 1.3327437e-03  6.5392954e-03  9.9839829e-03  9.0612099e-03\n",
            " -8.0165816e-03  6.4898157e-03 -5.7141553e-03 -9.6975203e-04\n",
            "  4.8343191e-04  6.5795328e-03  4.4718366e-03  4.6052895e-03\n",
            "  9.4817961e-03  3.8256825e-04 -6.0387240e-03 -6.3282927e-03\n",
            "  6.4314557e-03 -5.2422909e-03 -2.8506136e-03  4.0731020e-03\n",
            " -2.2925166e-03 -6.0254615e-03 -2.3240175e-03  1.2068190e-03\n",
            "  2.1831139e-03  6.0827993e-03 -5.2128206e-03  3.0776935e-03\n",
            "  7.2411140e-03  2.1951853e-03  5.3989454e-03 -4.8452769e-03\n",
            "  6.1542820e-03 -7.6011396e-03  3.4942867e-03 -9.3233129e-03\n",
            " -2.6039402e-03 -9.0756686e-03 -1.5863272e-03 -5.3644320e-03\n",
            " -3.9441618e-03  1.1517477e-03  2.8009464e-03 -1.5281484e-03\n",
            " -8.1679830e-03 -5.9202653e-03  8.2134194e-04 -3.9464738e-03\n",
            " -9.4292071e-03 -7.7411387e-04  6.6336337e-03  5.9791291e-03\n",
            " -9.9167544e-03  3.1199649e-03 -5.9851413e-03 -9.1812322e-03\n",
            "  1.7193661e-04 -3.6757113e-04 -6.9717309e-03 -6.2777917e-03\n",
            " -2.4257582e-03  7.0969719e-03 -7.5453324e-03  7.6990072e-03\n",
            " -4.7615601e-04  1.0938010e-03  9.4824648e-03  4.7280099e-03\n",
            " -3.5745706e-03  3.7378320e-03  3.5194873e-03  6.3353898e-03\n",
            "  7.1484697e-05 -4.4241608e-03  1.3182868e-03 -5.4147243e-03\n",
            "  1.4117184e-03  4.9270913e-03  5.1545375e-03  9.1809398e-03\n",
            " -7.5102835e-03 -5.4040286e-03  6.4676912e-03  1.3576420e-03\n",
            " -6.6095339e-03  8.8543701e-04  2.6765657e-03 -2.5282062e-03\n",
            " -4.9593360e-03  5.0068819e-03  9.6210111e-03 -7.3658973e-03\n",
            " -1.1462791e-04 -2.5647243e-03 -6.3644042e-03 -1.3795338e-03\n",
            " -5.2478239e-03  9.0592634e-03 -5.7884408e-03  3.6837477e-03]\n",
            "Similarity between 'word2vec' and 'learning': -0.1516\n",
            "Words most similar to 'natural': [('machine', 0.304378479719162), ('and', 0.17776663601398468), ('perform', 0.16441375017166138)]\n",
            "Word not in vocabulary: \"Key 'king' not present in vocabulary\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 불러오기: 저장된 Word2Vec 모델을 Word2Vec.load()를 사용하여 불러옵니다.\n",
        "단어 벡터: wv['word2vec']로 단어 'word2vec'의 벡터를 확인합니다.\n",
        "단어 간 유사도: similarity('word2vec', 'learning')를 통해 두 단어의 유사도를 측정합니다.\n",
        "유사한 단어 찾기: most_similar('natural')을 사용해 가장 유사한 단어들을 찾습니다.\n",
        "단어 벡터 연산: 'king' - 'man' + 'woman'과 유사한 단어를 찾는 산술 연산을 수행합니다. 모델에 해당 단어가 없을 경우를 대비해 예외 처리도 추가했습니다."
      ],
      "metadata": {
        "id": "0h88cIH-bsSB"
      },
      "id": "0h88cIH-bsSB"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}