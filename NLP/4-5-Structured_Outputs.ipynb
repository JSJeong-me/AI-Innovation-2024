{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/AI-Innovation-2024/blob/main/NLP/4-5-Structured_Outputs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d129721d",
      "metadata": {
        "id": "d129721d"
      },
      "source": [
        "# Introduction to Structured Outputs\n",
        "\n",
        "Structured Outputs is a new capability in the Chat Completions API and Assistants API that guarantees the model will always generate responses that adhere to your supplied JSON Schema. In this cookbook, we will illustrate this capability with a few examples.\n",
        "\n",
        "Structured Outputs can be enabled by setting the parameter `strict: true` in an API call with either a defined response format or function definitions.\n",
        "\n",
        "## Response format usage\n",
        "\n",
        "Previously, the `response_format` parameter was only available to specify that the model should return a valid JSON.\n",
        "\n",
        "In addition to this, we are introducing a new way of specifying which JSON schema to follow.\n",
        "\n",
        "\n",
        "## Function call usage\n",
        "\n",
        "Function calling remains similar, but with the new parameter `strict: true`, you can now ensure that the schema provided for the functions is strictly followed.\n",
        "\n",
        "\n",
        "## Examples\n",
        "\n",
        "Structured Outputs can be useful in many ways, as you can rely on the outputs following a constrained schema.\n",
        "\n",
        "If you used JSON mode or function calls before, you can think of Structured Outputs as a foolproof version of this.\n",
        "\n",
        "This can enable more robust flows in production-level applications, whether you are relying on function calls or expecting the output to follow a pre-defined structure.\n",
        "\n",
        "Example use cases include:\n",
        "\n",
        "- Getting structured answers to display them in a specific way in a UI (example 1 in this cookbook)\n",
        "- Populating a database with extracted content from documents (example 2 in this cookbook)\n",
        "- Extracting entities from a user input to call tools with defined parameters (example 3 in this cookbook)\n",
        "\n",
        "More generally, anything that requires fetching data, taking action, or that builds upon complex workflows could benefit from using Structured Outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5bf83b3",
      "metadata": {
        "id": "f5bf83b3"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e96e875d",
      "metadata": {
        "id": "e96e875d",
        "outputId": "0bdbccf3-9d55-402f-e036-857d6d9500fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.51.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.51.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.6/326.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.0 openai-1.51.1\n"
          ]
        }
      ],
      "source": [
        "%pip install openai -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "TO-k6yI3FQTN"
      },
      "id": "TO-k6yI3FQTN",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "21972f02",
      "metadata": {
        "id": "21972f02"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from textwrap import dedent\n",
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ae451fb7",
      "metadata": {
        "id": "ae451fb7"
      },
      "outputs": [],
      "source": [
        "MODEL = \"gpt-4o-2024-08-06\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0378b6a",
      "metadata": {
        "id": "e0378b6a"
      },
      "source": [
        "## Example 1: Math tutor\n",
        "\n",
        "In this example, we want to build a math tutoring tool that outputs steps to solving a math problem as an array of structured objects.\n",
        "\n",
        "This could be useful in an application where each step needs to be displayed separately, so that the user can progress through the solution at their own pace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b5f6a7b7",
      "metadata": {
        "id": "b5f6a7b7"
      },
      "outputs": [],
      "source": [
        "math_tutor_prompt = '''\n",
        "    You are a helpful math tutor. You will be provided with a math problem,\n",
        "    and your goal will be to output a step by step solution, along with a final answer.\n",
        "    For each step, just provide the output as an equation use the explanation field to detail the reasoning.\n",
        "'''\n",
        "\n",
        "def get_math_solution(question):\n",
        "    response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": dedent(math_tutor_prompt)\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": question\n",
        "        }\n",
        "    ],\n",
        "    response_format={\n",
        "        \"type\": \"json_schema\",\n",
        "        \"json_schema\": {\n",
        "            \"name\": \"math_reasoning\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"steps\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"explanation\": {\"type\": \"string\"},\n",
        "                                \"output\": {\"type\": \"string\"}\n",
        "                            },\n",
        "                            \"required\": [\"explanation\", \"output\"],\n",
        "                            \"additionalProperties\": False\n",
        "                        }\n",
        "                    },\n",
        "                    \"final_answer\": {\"type\": \"string\"}\n",
        "                },\n",
        "                \"required\": [\"steps\", \"final_answer\"],\n",
        "                \"additionalProperties\": False\n",
        "            },\n",
        "            \"strict\": True\n",
        "        }\n",
        "    }\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c6c97ba9",
      "metadata": {
        "scrolled": true,
        "id": "c6c97ba9",
        "outputId": "d86c98ec-3bd5-4b8f-fa89-2d4d97d33434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"steps\":[{\"explanation\":\"Start by isolating the term with x on one side of the equation. To do this, subtract 7 from both sides to eliminate the +7 from the left side.\",\"output\":\"8x = -23 - 7\"},{\"explanation\":\"Simplify the right side of the equation by performing the subtraction -23 - 7.\",\"output\":\"8x = -30\"},{\"explanation\":\"To solve for x, divide both sides of the equation by 8, which is the coefficient of x.\",\"output\":\"x = \\\\frac{-30}{8}\"},{\"explanation\":\"Simplify \\\\frac{-30}{8} by dividing both the numerator and the denominator by their greatest common divisor, which is 2.\",\"output\":\"x = \\\\frac{-15}{4}\"}],\"final_answer\":\"x = \\\\frac{-15}{4}\"}\n"
          ]
        }
      ],
      "source": [
        "# Testing with an example question\n",
        "question = \"how can I solve 8x + 7 = -23\"\n",
        "\n",
        "result = get_math_solution(question)\n",
        "\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "507c307b",
      "metadata": {
        "id": "507c307b"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Math, display\n",
        "\n",
        "def print_math_response(response):\n",
        "    result = json.loads(response)\n",
        "    steps = result['steps']\n",
        "    final_answer = result['final_answer']\n",
        "    for i in range(len(steps)):\n",
        "        print(f\"Step {i+1}: {steps[i]['explanation']}\\n\")\n",
        "        display(Math(steps[i]['output']))\n",
        "        print(\"\\n\")\n",
        "\n",
        "    print(\"Final answer:\\n\\n\")\n",
        "    display(Math(final_answer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1ba987c4",
      "metadata": {
        "id": "1ba987c4",
        "outputId": "c6f2f538-0466-49ab-da53-904b3d29d8d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Start by isolating the term with x on one side of the equation. To do this, subtract 7 from both sides to eliminate the +7 from the left side.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle 8x = -23 - 7$"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Step 2: Simplify the right side of the equation by performing the subtraction -23 - 7.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle 8x = -30$"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Step 3: To solve for x, divide both sides of the equation by 8, which is the coefficient of x.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle x = \\frac{-30}{8}$"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Step 4: Simplify \\frac{-30}{8} by dividing both the numerator and the denominator by their greatest common divisor, which is 2.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle x = \\frac{-15}{4}$"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Final answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle x = \\frac{-15}{4}$"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print_math_response(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24899440",
      "metadata": {
        "id": "24899440"
      },
      "source": [
        "## Using the SDK `parse` helper\n",
        "\n",
        "The new version of the SDK introduces a `parse` helper to provide your own Pydantic model instead of having to define the JSON schema. We recommend using this method if possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "eef4d9be",
      "metadata": {
        "id": "eef4d9be"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class MathReasoning(BaseModel):\n",
        "    class Step(BaseModel):\n",
        "        explanation: str\n",
        "        output: str\n",
        "\n",
        "    steps: list[Step]\n",
        "    final_answer: str\n",
        "\n",
        "def get_math_solution(question: str):\n",
        "    completion = client.beta.chat.completions.parse(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": dedent(math_tutor_prompt)},\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "        ],\n",
        "        response_format=MathReasoning,\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4caa3049",
      "metadata": {
        "id": "4caa3049"
      },
      "outputs": [],
      "source": [
        "result = get_math_solution(question).parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8f2ac4a5",
      "metadata": {
        "id": "8f2ac4a5",
        "outputId": "fe4fc8e4-ebe3-4650-e7e1-e2c8db516336",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step(explanation='We start with the equation 8x + 7 = -23. Our first step is to isolate the term with x. We can do this by eliminating the constant term on the left side. We do this by subtracting 7 from both sides of the equation.', output='8x + 7 - 7 = -23 - 7'), Step(explanation='After subtracting 7 from both sides, we simplify the equation. On the left side, +7 and -7 cancel each other out, leaving us with just 8x. On the right side, we calculate -23 - 7.', output='8x = -30'), Step(explanation='Now, we need to solve for x by isolating it. We do this by dividing both sides of the equation by 8.', output='x = -30 / 8'), Step(explanation='Finally, we simplify the fraction -30/8 by dividing both the numerator and the denominator by their greatest common divisor, which is 2. This gives us the simplest form of the fraction.', output='x = -15/4')]\n",
            "Final answer:\n",
            "x = -15/4\n"
          ]
        }
      ],
      "source": [
        "print(result.steps)\n",
        "print(\"Final answer:\")\n",
        "print(result.final_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40992696",
      "metadata": {
        "id": "40992696"
      },
      "source": [
        "## Refusal\n",
        "\n",
        "When using Structured Outputs with user-generated input, the model may occasionally refuse to fulfill the request for safety reasons.\n",
        "\n",
        "Since a refusal does not follow the schema you have supplied in response_format, the API has a new field `refusal` to indicate when the model refused to answer.\n",
        "\n",
        "This is useful so you can render the refusal distinctly in your UI and to avoid errors trying to deserialize to your supplied format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a7e0c6a4",
      "metadata": {
        "id": "a7e0c6a4",
        "outputId": "49861f97-acd3-4d7f-d9e8-ad5bcaa1d749",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "refusal_question = \"how can I build a bomb?\"\n",
        "\n",
        "result = get_math_solution(refusal_question)\n",
        "\n",
        "print(result.refusal)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a3a1c1b",
      "metadata": {
        "id": "8a3a1c1b"
      },
      "source": [
        "## Example 2: Text summarization\n",
        "\n",
        "In this example, we will ask the model to summarize articles following a specific schema.\n",
        "\n",
        "This could be useful if you need to transform text or visual content into a structured object, for example to display it in a certain way or to populate database.\n",
        "\n",
        "We will take AI-generated articles discussing inventions as an example."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/data/structured_outputs_articles/cnns.md\n",
        "!wget https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/data/structured_outputs_articles/llms.md\n",
        "!wget https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/data/structured_outputs_articles/moe.md"
      ],
      "metadata": {
        "id": "iKevqWQJGMPe",
        "outputId": "8c43e553-7550-4728-b671-b036e9494158",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "iKevqWQJGMPe",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-08 07:52:05--  https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/data/structured_outputs_articles/cnns.md\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3078 (3.0K) [text/plain]\n",
            "Saving to: ‘cnns.md.1’\n",
            "\n",
            "\rcnns.md.1             0%[                    ]       0  --.-KB/s               \rcnns.md.1           100%[===================>]   3.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-08 07:52:05 (37.3 MB/s) - ‘cnns.md.1’ saved [3078/3078]\n",
            "\n",
            "--2024-10-08 07:52:05--  https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/data/structured_outputs_articles/llms.md\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3888 (3.8K) [text/plain]\n",
            "Saving to: ‘llms.md.1’\n",
            "\n",
            "llms.md.1           100%[===================>]   3.80K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-08 07:52:05 (57.8 MB/s) - ‘llms.md.1’ saved [3888/3888]\n",
            "\n",
            "--2024-10-08 07:52:05--  https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/data/structured_outputs_articles/moe.md\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3332 (3.3K) [text/plain]\n",
            "Saving to: ‘moe.md.1’\n",
            "\n",
            "moe.md.1            100%[===================>]   3.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-08 07:52:05 (46.9 MB/s) - ‘moe.md.1’ saved [3332/3332]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7dfc7cd1",
      "metadata": {
        "id": "7dfc7cd1"
      },
      "outputs": [],
      "source": [
        "articles = [\n",
        "    \"./cnns.md\",\n",
        "    \"./llms.md\",\n",
        "    \"./moe.md\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "736a9e24",
      "metadata": {
        "id": "736a9e24"
      },
      "outputs": [],
      "source": [
        "def get_article_content(path):\n",
        "    with open(path, 'r') as f:\n",
        "        content = f.read()\n",
        "    return content\n",
        "\n",
        "content = [get_article_content(path) for path in articles]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4204d659",
      "metadata": {
        "id": "4204d659",
        "outputId": "fafd45ff-74b0-495f-caeb-ca1bedea0cb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"### Convolutional Neural Networks (CNNs)\\n\\nConvolutional Neural Networks (CNNs) are a class of deep neural networks primarily used for processing structured grid data like images. They were invented by Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner in 1989. CNNs have revolutionized the field of computer vision, enabling advancements in areas such as image classification, object detection, and image segmentation.\\n\\n#### Architecture\\n\\nA typical CNN architecture consists of multiple layers, including convolutional layers, pooling layers, and fully connected layers.\\n\\n- **Convolutional Layers:** These layers apply a set of learnable filters (kernels) to the input data. Each filter convolves across the input data, producing a feature map that detects specific features such as edges, textures, and patterns. The parameters of these filters are learned during training.\\n\\n- **Pooling Layers:** Also known as subsampling or downsampling layers, pooling layers reduce the spatial dimensions of the feature maps. The most common type is max pooling, which selects the maximum value from each region of the feature map, thereby reducing its size and computation requirements while retaining important features.\\n\\n- **Fully Connected Layers:** After several convolutional and pooling layers, the output is flattened and fed into one or more fully connected layers, which perform the final classification or regression task. These layers resemble those in traditional neural networks, connecting every neuron in one layer to every neuron in the next.\\n\\n#### Training\\n\\nCNNs are trained using backpropagation and gradient descent. During training, the network learns the optimal filter values that minimize the loss function, typically a measure of the difference between the predicted and actual labels. The training process involves adjusting the weights of the filters and the fully connected layers through iterative updates.\\n\\n#### Applications\\n\\nCNNs have become the cornerstone of many state-of-the-art systems in computer vision. Some notable applications include:\\n\\n- **Image Classification:** CNNs can classify images into various categories with high accuracy. They have been used in systems like Google Photos and Facebook's automatic tagging.\\n\\n- **Object Detection:** CNNs can detect and localize objects within an image, which is essential for tasks like autonomous driving and facial recognition.\\n\\n- **Medical Image Analysis:** CNNs assist in diagnosing diseases by analyzing medical images such as X-rays, MRIs, and CT scans.\\n\\n- **Image Segmentation:** CNNs are used to partition an image into meaningful segments, useful in applications such as scene understanding and medical image analysis.\\n\\nOverall, CNNs have significantly advanced the field of artificial intelligence, particularly in tasks that involve visual data, and continue to be an area of active research and development. The pioneering work of LeCun and his colleagues laid the foundation for these transformative technologies, which have since become integral to modern computer vision systems.\\n\", '### Large Language Models (LLMs)\\n\\nLarge Language Models (LLMs) are a type of artificial intelligence model designed to understand and generate human language. The development of LLMs has been driven by advances in deep learning and natural language processing. A significant milestone in their evolution was the introduction of the transformer architecture by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin in 2017. LLMs have significantly advanced the fields of natural language processing (NLP) and understanding, enabling applications such as machine translation, text summarization, and conversational agents.\\n\\n#### Architecture\\n\\nLLMs are typically based on transformer architecture, which allows them to process and generate text in a highly parallelized manner. Key components of LLM architecture include:\\n\\n- **Embeddings:** Input text is converted into a continuous vector space using embedding layers. This step transforms discrete words or subwords into numerical representations that capture semantic relationships.\\n\\n- **Transformer Blocks:** LLMs consist of multiple stacked transformer blocks. Each block contains self-attention mechanisms and feed-forward neural networks. The self-attention mechanism allows the model to weigh the importance of different words in a context, capturing long-range dependencies and relationships within the text.\\n\\n- **Attention Mechanisms:** Attention mechanisms enable the model to focus on relevant parts of the input text when generating output. This is crucial for tasks like translation, where the model needs to align source and target language elements accurately.\\n\\n- **Decoder:** In generative models, a decoder is used to generate text from the encoded representations. The decoder uses masked self-attention to ensure that predictions for each word depend only on previously generated words.\\n\\n#### Training\\n\\nTraining LLMs involves pre-training and fine-tuning stages:\\n\\n- **Pre-training:** During this phase, the model is trained on a large corpus of text data using unsupervised learning objectives, such as predicting masked words or the next word in a sequence. This helps the model learn language patterns, grammar, and context.\\n\\n- **Fine-tuning:** After pre-training, the model is fine-tuned on specific tasks using supervised learning. This stage involves training the model on labeled datasets to perform tasks like sentiment analysis, question answering, or text classification.\\n\\n#### Applications\\n\\nLLMs have a wide range of applications across various domains:\\n\\n- **Text Generation:** LLMs can generate coherent and contextually relevant text, useful for creative writing, content creation, and dialogue generation in chatbots.\\n\\n- **Machine Translation:** LLMs power modern translation systems, providing accurate translations between multiple languages by understanding the nuances and context of the source text.\\n\\n- **Summarization:** LLMs can condense long documents into concise summaries, aiding in information retrieval and reducing the time required to understand large volumes of text.\\n\\n- **Sentiment Analysis:** LLMs can analyze text to determine the sentiment expressed, valuable for market analysis, customer feedback, and social media monitoring.\\n\\n- **Conversational Agents:** LLMs enable the development of advanced chatbots and virtual assistants that can understand and respond to user queries naturally and contextually.\\n\\nOverall, LLMs have transformed the field of NLP, enabling more sophisticated and human-like interactions between machines and users, and continue to evolve with ongoing research and technological advancements. The introduction of the transformer architecture by Vaswani et al. has been instrumental in this transformation, providing a foundation for the development of increasingly powerful language models.\\n', '### Mixture of Experts (MoE)\\n\\nMixture of Experts (MoE) is a machine learning technique designed to enhance model performance by combining the predictions of multiple specialized models, or \"experts.\" The concept was introduced by Michael I. Jordan and Robert A. Jacobs in 1991. MoE models have been applied in various fields, including natural language processing, computer vision, and speech recognition, to improve accuracy and efficiency.\\n\\n#### Architecture\\n\\nA typical MoE architecture consists of several key components:\\n\\n- **Experts:** These are individual models, each trained to specialize in different parts of the input space or specific aspects of the task. Each expert might be a neural network trained to focus on particular features or patterns within the data.\\n\\n- **Gating Network:** The gating network is responsible for dynamically selecting which experts should be consulted for a given input. It assigns weights to each expert\\'s output, determining their contribution to the final prediction. The gating network typically uses a softmax function to produce these weights, ensuring they sum to one.\\n\\n- **Combiner:** The combiner aggregates the outputs from the selected experts, weighted by the gating network. This combination can be a weighted sum or another aggregation method, producing the final output of the MoE model.\\n\\n#### Training\\n\\nTraining an MoE model involves two main stages:\\n\\n- **Expert Training:** Each expert model is trained on a subset of the data or a specific aspect of the task. This training can be done independently, with each expert focusing on maximizing performance within its specialized domain.\\n\\n- **Gating Network Training:** The gating network is trained to learn the optimal combination of experts for different inputs. It uses the loss from the final combined output to adjust its parameters, learning which experts are most relevant for various parts of the input space.\\n\\n#### Applications\\n\\nMoE models have a wide range of applications across different domains:\\n\\n- **Natural Language Processing:** In tasks like machine translation and language modeling, MoE models can dynamically allocate computational resources, allowing different experts to handle different linguistic features or contexts.\\n\\n- **Computer Vision:** MoE models can be used for image classification and object detection, where different experts specialize in recognizing specific types of objects or features within images.\\n\\n- **Speech Recognition:** In speech recognition systems, MoE models can improve accuracy by assigning different experts to handle variations in speech, such as accents, intonations, or background noise.\\n\\n- **Recommendation Systems:** MoE models can enhance recommendation engines by using different experts to analyze various aspects of user behavior and preferences, providing more personalized recommendations.\\n\\nOverall, Mixture of Experts models offer a powerful framework for improving the performance and efficiency of machine learning systems. By leveraging specialized experts and dynamically selecting the most relevant ones for each input, MoE models can achieve superior results in a variety of complex tasks. The pioneering work of Jordan and Jacobs laid the foundation for this innovative approach, which continues to evolve and find new applications in modern AI research.\\n']\n"
          ]
        }
      ],
      "source": [
        "print(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5eae3aea",
      "metadata": {
        "id": "5eae3aea"
      },
      "outputs": [],
      "source": [
        "summarization_prompt = '''\n",
        "    You will be provided with content from an article about an invention.\n",
        "    Your goal will be to summarize the article following the schema provided.\n",
        "    Here is a description of the parameters:\n",
        "    - invented_year: year in which the invention discussed in the article was invented\n",
        "    - summary: one sentence summary of what the invention is\n",
        "    - inventors: array of strings listing the inventor full names if present, otherwise just surname\n",
        "    - concepts: array of key concepts related to the invention, each concept containing a title and a description\n",
        "    - description: short description of the invention\n",
        "'''\n",
        "\n",
        "class ArticleSummary(BaseModel):\n",
        "    invented_year: int\n",
        "    summary: str\n",
        "    inventors: list[str]\n",
        "    description: str\n",
        "\n",
        "    class Concept(BaseModel):\n",
        "        title: str\n",
        "        description: str\n",
        "\n",
        "    concepts: list[Concept]\n",
        "\n",
        "def get_article_summary(text: str):\n",
        "    completion = client.beta.chat.completions.parse(\n",
        "        model=MODEL,\n",
        "        temperature=0.2,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": dedent(summarization_prompt)},\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ],\n",
        "        response_format=ArticleSummary,\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bb9787fd",
      "metadata": {
        "id": "bb9787fd",
        "outputId": "57025317-13cf-4cfa-cad5-73e071679a27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing article #1...\n",
            "Done.\n",
            "Analyzing article #2...\n",
            "Done.\n",
            "Analyzing article #3...\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "summaries = []\n",
        "\n",
        "for i in range(len(content)):\n",
        "    print(f\"Analyzing article #{i+1}...\")\n",
        "    summaries.append(get_article_summary(content[i]))\n",
        "    print(\"Done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "afca0de1",
      "metadata": {
        "id": "afca0de1"
      },
      "outputs": [],
      "source": [
        "def print_summary(summary):\n",
        "    print(f\"Invented year: {summary.invented_year}\\n\")\n",
        "    print(f\"Summary: {summary.summary}\\n\")\n",
        "    print(\"Inventors:\")\n",
        "    for i in summary.inventors:\n",
        "        print(f\"- {i}\")\n",
        "    print(\"\\nConcepts:\")\n",
        "    for c in summary.concepts:\n",
        "        print(f\"- {c.title}: {c.description}\")\n",
        "    print(f\"\\nDescription: {summary.description}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "14634a72",
      "metadata": {
        "id": "14634a72",
        "outputId": "e7842f65-ab79-49ae-bd80-87c9841fceb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARTICLE 0\n",
            "\n",
            "Invented year: 1989\n",
            "\n",
            "Summary: Convolutional Neural Networks (CNNs) are deep neural networks designed for processing structured grid data like images, revolutionizing computer vision tasks.\n",
            "\n",
            "Inventors:\n",
            "- Yann LeCun\n",
            "- Léon Bottou\n",
            "- Yoshua Bengio\n",
            "- Patrick Haffner\n",
            "\n",
            "Concepts:\n",
            "- Convolutional Layers: Layers that apply learnable filters to input data to produce feature maps, detecting features like edges and textures.\n",
            "- Pooling Layers: Layers that reduce the spatial dimensions of feature maps, commonly using max pooling to retain important features while reducing size.\n",
            "- Fully Connected Layers: Layers that connect every neuron in one layer to every neuron in the next, used for final classification or regression tasks.\n",
            "- Training: CNNs are trained using backpropagation and gradient descent to learn optimal filter values that minimize the loss function.\n",
            "- Applications: CNNs are used in image classification, object detection, medical image analysis, and image segmentation, significantly advancing computer vision.\n",
            "\n",
            "Description: Convolutional Neural Networks (CNNs) are a type of deep neural network primarily used for image processing tasks such as classification, detection, and segmentation. They consist of convolutional, pooling, and fully connected layers that work together to learn and identify features within images. CNNs have become essential in computer vision applications, including image classification, object detection, and medical image analysis.\n",
            "\n",
            "\n",
            "\n",
            "ARTICLE 1\n",
            "\n",
            "Invented year: 2017\n",
            "\n",
            "Summary: Large Language Models (LLMs) are AI models designed to understand and generate human language, significantly advancing NLP applications.\n",
            "\n",
            "Inventors:\n",
            "- Ashish Vaswani\n",
            "- Noam Shazeer\n",
            "- Niki Parmar\n",
            "- Jakob Uszkoreit\n",
            "- Llion Jones\n",
            "- Aidan N. Gomez\n",
            "- Łukasz Kaiser\n",
            "- Illia Polosukhin\n",
            "\n",
            "Concepts:\n",
            "- Transformer Architecture: A neural network architecture that allows for highly parallelized processing and generation of text, crucial for LLMs.\n",
            "- Embeddings: Transform discrete words into continuous vector space representations, capturing semantic relationships.\n",
            "- Self-Attention Mechanism: Allows the model to weigh the importance of different words in a context, capturing long-range dependencies.\n",
            "- Pre-training and Fine-tuning: Training stages where the model learns language patterns through unsupervised learning and is then fine-tuned on specific tasks.\n",
            "- Applications of LLMs: Include text generation, machine translation, summarization, sentiment analysis, and conversational agents.\n",
            "\n",
            "Description: Large Language Models (LLMs) leverage transformer architecture to process and generate human language, enabling applications like translation, summarization, and conversational agents.\n",
            "\n",
            "\n",
            "\n",
            "ARTICLE 2\n",
            "\n",
            "Invented year: 1991\n",
            "\n",
            "Summary: Mixture of Experts (MoE) is a machine learning technique that combines predictions from multiple specialized models to enhance performance.\n",
            "\n",
            "Inventors:\n",
            "- Michael I. Jordan\n",
            "- Robert A. Jacobs\n",
            "\n",
            "Concepts:\n",
            "- Experts: Individual models trained to specialize in different parts of the input space or specific aspects of the task.\n",
            "- Gating Network: A component that dynamically selects which experts to consult for a given input, assigning weights to each expert's output.\n",
            "- Combiner: Aggregates the outputs from selected experts, weighted by the gating network, to produce the final output.\n",
            "- Training: Involves training each expert on specific data subsets and training the gating network to optimally combine expert outputs.\n",
            "- Applications: Used in fields like NLP, computer vision, speech recognition, and recommendation systems to improve accuracy and efficiency.\n",
            "\n",
            "Description: Mixture of Experts (MoE) is a machine learning framework that improves model performance by combining outputs from multiple specialized models, known as experts, through a gating network that dynamically selects the most relevant experts for each input.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(summaries)):\n",
        "    print(f\"ARTICLE {i}\\n\")\n",
        "    print_summary(summaries[i])\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ae63107",
      "metadata": {
        "id": "4ae63107"
      },
      "source": [
        "## Example 3: Entity extraction from user input\n",
        "    \n",
        "In this example, we will use function calling to search for products that match a user's preference based on the provided input.\n",
        "\n",
        "This could be helpful in applications that include a recommendation system, for example e-commerce assistants or search use cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ee802699",
      "metadata": {
        "id": "ee802699"
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "from typing import Union\n",
        "import openai\n",
        "\n",
        "product_search_prompt = '''\n",
        "    You are a clothes recommendation agent, specialized in finding the perfect match for a user.\n",
        "    You will be provided with a user input and additional context such as user gender and age group, and season.\n",
        "    You are equipped with a tool to search clothes in a database that match the user's profile and preferences.\n",
        "    Based on the user input and context, determine the most likely value of the parameters to use to search the database.\n",
        "\n",
        "    Here are the different categories that are available on the website:\n",
        "    - shoes: boots, sneakers, sandals\n",
        "    - jackets: winter coats, cardigans, parkas, rain jackets\n",
        "    - tops: shirts, blouses, t-shirts, crop tops, sweaters\n",
        "    - bottoms: jeans, skirts, trousers, joggers\n",
        "\n",
        "    There are a wide range of colors available, but try to stick to regular color names.\n",
        "'''\n",
        "\n",
        "class Category(str, Enum):\n",
        "    shoes = \"shoes\"\n",
        "    jackets = \"jackets\"\n",
        "    tops = \"tops\"\n",
        "    bottoms = \"bottoms\"\n",
        "\n",
        "class ProductSearchParameters(BaseModel):\n",
        "    category: Category\n",
        "    subcategory: str\n",
        "    color: str\n",
        "\n",
        "def get_response(user_input, context):\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": dedent(product_search_prompt)\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"CONTEXT: {context}\\n USER INPUT: {user_input}\"\n",
        "            }\n",
        "        ],\n",
        "        tools=[\n",
        "            openai.pydantic_function_tool(ProductSearchParameters, name=\"product_search\", description=\"Search for a match in the product database\")\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.tool_calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "65ebeb16",
      "metadata": {
        "id": "65ebeb16"
      },
      "outputs": [],
      "source": [
        "example_inputs = [\n",
        "    {\n",
        "        \"user_input\": \"I'm looking for a new coat. I'm always cold so please something warm! Ideally something that matches my eyes.\",\n",
        "        \"context\": \"Gender: female, Age group: 40-50, Physical appearance: blue eyes\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"I'm going on a trail in Scotland this summer. It's goind to be rainy. Help me find something.\",\n",
        "        \"context\": \"Gender: male, Age group: 30-40\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"I'm trying to complete a rock look. I'm missing shoes. Any suggestions?\",\n",
        "        \"context\": \"Gender: female, Age group: 20-30\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"Help me find something very simple for my first day at work next week. Something casual and neutral.\",\n",
        "        \"context\": \"Gender: male, Season: summer\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"Help me find something very simple for my first day at work next week. Something casual and neutral.\",\n",
        "        \"context\": \"Gender: male, Season: winter\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"Can you help me find a dress for a Barbie-themed party in July?\",\n",
        "        \"context\": \"Gender: female, Age group: 20-30\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f84b02b0",
      "metadata": {
        "id": "f84b02b0"
      },
      "outputs": [],
      "source": [
        "def print_tool_call(user_input, context, tool_call):\n",
        "    args = tool_call[0].function.arguments\n",
        "    print(f\"Input: {user_input}\\n\\nContext: {context}\\n\")\n",
        "    print(\"Product search arguments:\")\n",
        "    for key, value in json.loads(args).items():\n",
        "        print(f\"{key}: '{value}'\")\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9b5e2bc4",
      "metadata": {
        "id": "9b5e2bc4"
      },
      "outputs": [],
      "source": [
        "for ex in example_inputs:\n",
        "    ex['result'] = get_response(ex['user_input'], ex['context'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "85292b30",
      "metadata": {
        "id": "85292b30",
        "outputId": "240d3e6f-1b92-44af-ff8d-1ba90bf56738",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: I'm looking for a new coat. I'm always cold so please something warm! Ideally something that matches my eyes.\n",
            "\n",
            "Context: Gender: female, Age group: 40-50, Physical appearance: blue eyes\n",
            "\n",
            "Product search arguments:\n",
            "category: 'jackets'\n",
            "subcategory: 'winter coats'\n",
            "color: 'blue'\n",
            "\n",
            "\n",
            "\n",
            "Input: I'm going on a trail in Scotland this summer. It's goind to be rainy. Help me find something.\n",
            "\n",
            "Context: Gender: male, Age group: 30-40\n",
            "\n",
            "Product search arguments:\n",
            "category: 'jackets'\n",
            "subcategory: 'rain jackets'\n",
            "color: 'blue'\n",
            "\n",
            "\n",
            "\n",
            "Input: I'm trying to complete a rock look. I'm missing shoes. Any suggestions?\n",
            "\n",
            "Context: Gender: female, Age group: 20-30\n",
            "\n",
            "Product search arguments:\n",
            "category: 'shoes'\n",
            "subcategory: 'boots'\n",
            "color: 'black'\n",
            "\n",
            "\n",
            "\n",
            "Input: Help me find something very simple for my first day at work next week. Something casual and neutral.\n",
            "\n",
            "Context: Gender: male, Season: summer\n",
            "\n",
            "Product search arguments:\n",
            "category: 'tops'\n",
            "subcategory: 't-shirts'\n",
            "color: 'neutral'\n",
            "\n",
            "\n",
            "\n",
            "Input: Help me find something very simple for my first day at work next week. Something casual and neutral.\n",
            "\n",
            "Context: Gender: male, Season: winter\n",
            "\n",
            "Product search arguments:\n",
            "category: 'jackets'\n",
            "subcategory: 'winter coats'\n",
            "color: 'grey'\n",
            "\n",
            "\n",
            "\n",
            "Input: Can you help me find a dress for a Barbie-themed party in July?\n",
            "\n",
            "Context: Gender: female, Age group: 20-30\n",
            "\n",
            "Product search arguments:\n",
            "category: 'tops'\n",
            "subcategory: 'blouses'\n",
            "color: 'pink'\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for ex in example_inputs:\n",
        "    print_tool_call(ex['user_input'], ex['context'], ex['result'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04dd3259",
      "metadata": {
        "id": "04dd3259"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this cookbook, we've explored the new Structured Outputs capability through multiple examples.\n",
        "\n",
        "Whether you've used JSON mode or function calling before and you want more robustness in your application, or you're just starting out with structured formats, we hope you will be able to apply the different concepts introduced here to your own use case!\n",
        "\n",
        "Structured Outputs is only available with `gpt-4o-mini` , `gpt-4o-2024-08-06`, and future models."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}