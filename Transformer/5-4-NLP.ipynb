{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/AI-Innovation-2024/blob/main/Transformer/5-4-NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhQzKm1KpIho"
      },
      "source": [
        "# Lesson 2: Natural Language Processing (NLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XluOeRWJpIhr"
      },
      "source": [
        "- Here is some code that suppresses warning messages."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "mR-89y5_pOr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "GMlitf4UpIhs"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Use your Hugging Face token here\n",
        "login(token=\"hf_\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import userdata\n",
        "# userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "3vCH5J6opi_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yBycg6UEp44o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "67rfD41vpIht"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3_Fqn2_pIht"
      },
      "source": [
        "- Define the conversation pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlenderbotForConditionalGeneration, BlenderbotTokenizer\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = \"facebook/blenderbot-400M-distill\"\n",
        "tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
        "model = BlenderbotForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Function to chat with the model\n",
        "def chat(input_text):\n",
        "    inputs = tokenizer([input_text], return_tensors='pt')\n",
        "    reply_ids = model.generate(**inputs)\n",
        "    reply = tokenizer.batch_decode(reply_ids, skip_special_tokens=True)[0]\n",
        "    return reply\n",
        "\n",
        "# Example usage\n",
        "response = chat(\"Hi, how are you?\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "vrLy-HhBqrUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "TWg_9iQTpIht"
      },
      "outputs": [],
      "source": [
        "# chatbot = pipeline(task=\"conversational\",\n",
        "#                    model=\"facebook/blenderbot-400M-distill\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytRUHScfpIht"
      },
      "source": [
        "Info about ['blenderbot-400M-distill'](https://huggingface.co/facebook/blenderbot-400M-distill)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "LF9Ch09OpIhu"
      },
      "outputs": [],
      "source": [
        "user_message = \"\"\"\n",
        "What are some fun activities I can do in the winter?\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "46WT7qP6pIhu"
      },
      "outputs": [],
      "source": [
        "conversation = Conversation(user_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "qJ3uNkVcpIhv"
      },
      "outputs": [],
      "source": [
        "print(conversation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "-8Al8LnHpIhv"
      },
      "outputs": [],
      "source": [
        "conversation = chatbot(conversation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "vbefNvMlpIhv"
      },
      "outputs": [],
      "source": [
        "print(conversation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7bRfL2HpIhv"
      },
      "source": [
        "- You can continue the conversation with the chatbot with:\n",
        "```\n",
        "print(chatbot(Conversation(\"What else do you recommend?\")))\n",
        "```\n",
        "- However, the chatbot may provide an unrelated response because it does not have memory of any prior conversations.\n",
        "\n",
        "- To include prior conversations in the LLM's context, you can add a 'message' to include the previous chat history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 115,
        "id": "DmUXBMAIpIhw"
      },
      "outputs": [],
      "source": [
        "conversation.add_message(\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": \"\"\"\n",
        "What else do you recommend?\n",
        "\"\"\"\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "NNI2-vLIpIhw"
      },
      "outputs": [],
      "source": [
        "print(conversation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "lCJXFeIQpIhw"
      },
      "outputs": [],
      "source": [
        "conversation = chatbot(conversation)\n",
        "\n",
        "print(conversation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttfnRd7ZpIhw"
      },
      "source": [
        "- [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n",
        "- [LMSYS Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "0OdFwG78pIhx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}