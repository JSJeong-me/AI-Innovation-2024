{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN+TqV/ONqTpR960Rec+lpF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/AI-Innovation-2024/blob/main/RL/6-3-Taxi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsX_OSqKKb4V",
        "outputId": "85ef202d-11b8-43b8-9591-c6b2ef6ea453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에피소드: 9000\n",
            "학습 완료!\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Taxi-v3 환경 불러오기\n",
        "env = gym.make(\"Taxi-v3\").env\n",
        "\n",
        "# Q-테이블 초기화\n",
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "alpha = 0.1  # 학습률\n",
        "gamma = 0.6  # 할인율\n",
        "epsilon = 0.1  # 탐험 확률\n",
        "\n",
        "# 학습 에피소드 수\n",
        "num_episodes = 10000\n",
        "\n",
        "# 학습 프로세스\n",
        "for i in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    epochs, penalties, reward, = 0, 0, 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            # 무작위 액션(탐험)\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            # 최적의 액션(활용)\n",
        "            action = np.argmax(q_table[state])\n",
        "\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "\n",
        "        # Q-값 업데이트\n",
        "        old_value = q_table[state, action]\n",
        "        next_max = np.max(q_table[next_state])\n",
        "\n",
        "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "        q_table[state, action] = new_value\n",
        "\n",
        "        # 상태 업데이트\n",
        "        state = next_state\n",
        "\n",
        "        # 패널티가 있을 경우 기록\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        epochs += 1\n",
        "\n",
        "    # 1000 에피소드마다 진행 상황 출력\n",
        "    if i % 1000 == 0:\n",
        "        clear_output(wait=True)\n",
        "        print(f\"에피소드: {i}\")\n",
        "\n",
        "print(\"학습 완료!\")\n",
        "\n",
        "# 성능 평가\n",
        "total_epochs, total_penalties = 0, 0\n",
        "episodes = 100\n",
        "\n",
        "for _ in range(episodes):\n",
        "    state = env.reset()\n",
        "    epochs, penalties, reward = 0, 0, 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = np.argmax(q_table[state])\n",
        "        state, reward, done, info = env.step(action)\n",
        "\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        epochs += 1\n",
        "\n",
        "    total_penalties += penalties\n",
        "    total_epochs += epochs\n",
        "\n",
        "print(f\"에피소드 {episodes} 동안 평균 시간 스텝: {total_epochs / episodes}\")\n",
        "print(f\"에피소드 {episodes} 동안 평균 패널티: {total_penalties / episodes}\")\n"
      ]
    }
  ]
}