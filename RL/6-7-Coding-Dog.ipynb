{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw+WJxzI6Se7E7UWs7uJ32",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/AI-Innovation-2024/blob/main/RL/6-7-Coding-Dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nCaL03rDKveq",
        "outputId": "fd545ceb-60fb-47ca-e96f-eb9c9c0b1b9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogen\n",
            "  Downloading autogen-0.3.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting diskcache (from autogen)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from autogen)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting flaml (from autogen)\n",
            "  Downloading FLAML-2.3.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from autogen) (1.26.4)\n",
            "Collecting openai>=1.3 (from autogen)\n",
            "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from autogen) (24.1)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from autogen) (2.9.2)\n",
            "Collecting python-dotenv (from autogen)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from autogen) (2.5.0)\n",
            "Collecting tiktoken (from autogen)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.3->autogen) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.3->autogen)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.3->autogen)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->autogen) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->autogen) (2.23.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->autogen) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->autogen) (2.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->autogen) (2024.9.11)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->autogen) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->autogen) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->autogen) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.3->autogen)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->autogen)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->autogen) (3.4.0)\n",
            "Downloading autogen-0.3.1-py3-none-any.whl (350 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m350.1/350.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading FLAML-2.3.1-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.3/313.3 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, jiter, h11, flaml, diskcache, tiktoken, httpcore, docker, httpx, openai, autogen\n",
            "Successfully installed autogen-0.3.1 diskcache-5.6.3 docker-7.1.0 flaml-2.3.1 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.52.2 python-dotenv-1.0.1 tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install autogen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import openai\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "openai.api_key  = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "g_8UBxW_KzrD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from autogen.coding import CodeBlock, LocalCommandLineCodeExecutor\n",
        "\n",
        "work_dir = Path(\"coding\")\n",
        "work_dir.mkdir(exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hq5eeZIKwAG",
        "outputId": "f29d7062-2c57-4693-bbdd-fd27c4298fca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "executor = LocalCommandLineCodeExecutor(work_dir=work_dir)\n",
        "# print(\n",
        "#     executor.execute_code_blocks(\n",
        "#         code_blocks=[\n",
        "#             CodeBlock(language=\"python\", code=\"print('Hello, World!')\"),\n",
        "#         ]\n",
        "#     )\n",
        "# )"
      ],
      "metadata": {
        "id": "d5OuIUzILN8K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "executor.execute_code_blocks(\n",
        "        code_blocks=[\n",
        "            CodeBlock(language=\"python\", code=\"print('Hello, World!')\"),\n",
        "        ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSkjAN9lLbmk",
        "outputId": "98ae18ae-cb87-4cf8-e7f7-e692708284ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommandLineCodeResult(exit_code=0, output='Hello, World!\\n', code_file='/content/coding/tmp_code_07da107bb575cc4e02b0e1d6d99cc204.py')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from autogen import ConversableAgent\n",
        "from autogen.coding import LocalCommandLineCodeExecutor\n",
        "\n",
        "work_dir = Path(\"coding\")\n",
        "work_dir.mkdir(exist_ok=True)\n",
        "\n",
        "executor = LocalCommandLineCodeExecutor(work_dir=work_dir)\n",
        "\n",
        "code_executor_agent = ConversableAgent(\n",
        "    name=\"coding_dog\",\n",
        "    llm_config=False,\n",
        "    code_execution_config={\n",
        "        \"executor\": executor,\n",
        "    },\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ],
      "metadata": {
        "id": "sSQJfjotLz-d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code writer agent's system message is to instruct the LLM on how to\n",
        "# use the Jupyter code executor with IPython kernel.\n",
        "code_writer_system_message = \"\"\"\n",
        "You have been given coding capability to solve tasks using Python code.\n",
        "In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n",
        "    1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n",
        "    2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\n",
        "Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\n",
        "When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\n",
        "If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "\n",
        "code_writer_agent = ConversableAgent(\n",
        "    \"code_writer\",\n",
        "    system_message=code_writer_system_message,\n",
        "    llm_config={\"config_list\": [{\"model\": \"ft:gpt-3.5-turbo-0613:shinkisa::8VomhV43\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},   # gpt-4\n",
        "    code_execution_config=False,  # Turn off code execution for this agent.\n",
        "    max_consecutive_auto_reply=2,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ],
      "metadata": {
        "id": "NtH3K0y8NOWo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "chat_result = code_executor_agent.initiate_chat(\n",
        "    code_writer_agent, message=\"Write Python code to calculate the 14th Fibonacci number.\"\n",
        ")\n",
        "\n",
        "pprint.pprint(chat_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0ivGlSSMmXo",
        "outputId": "d5a06137-c4e4-42b3-9fb4-ac64495f64b2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coding_dog (to code_writer):\n",
            "\n",
            "Write Python code to calculate the 14th Fibonacci number.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 10-28 04:18:18] {409} WARNING - Model ft:gpt-3.5-turbo-0613:shinkisa::8VomhV43 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model ft:gpt-3.5-turbo-0613:shinkisa::8VomhV43 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "code_writer (to coding_dog):\n",
            "\n",
            "To calculate the 14th Fibonacci number, we can use a recursive function or iteration.\n",
            "\n",
            "1. Using recursion:\n",
            "```python\n",
            "def fibonacci(n):\n",
            "    if n <= 1:\n",
            "        return n\n",
            "    else:\n",
            "        return fibonacci(n-1) + fibonacci(n-2)\n",
            "\n",
            "fibonacci_number = fibonacci(14)\n",
            "print(fibonacci_number)\n",
            "```\n",
            "\n",
            "2. Using iteration:\n",
            "```python\n",
            "def fibonacci(n):\n",
            "    if n <= 1:\n",
            "        return n\n",
            "    else:\n",
            "        a, b = 0, 1\n",
            "        for _ in range(n-1):\n",
            "            a, b = b, a + b\n",
            "        return b\n",
            "\n",
            "fibonacci_number = fibonacci(14)\n",
            "print(fibonacci_number)\n",
            "```\n",
            "\n",
            "Both approaches will give the same result: the 14th Fibonacci number is 377.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING 2 CODE BLOCKS (inferred languages are [python, python])...\n",
            "coding_dog (to code_writer):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: 377\n",
            "377\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 10-28 04:18:21] {409} WARNING - Model ft:gpt-3.5-turbo-0613:shinkisa::8VomhV43 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model ft:gpt-3.5-turbo-0613:shinkisa::8VomhV43 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "code_writer (to coding_dog):\n",
            "\n",
            "Correct! The 14th Fibonacci number is indeed 377.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "coding_dog (to code_writer):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ChatResult(chat_id=None,\n",
            "           chat_history=[{'content': 'Write Python code to calculate the 14th '\n",
            "                                     'Fibonacci number.',\n",
            "                          'name': 'coding_dog',\n",
            "                          'role': 'assistant'},\n",
            "                         {'content': 'To calculate the 14th Fibonacci number, '\n",
            "                                     'we can use a recursive function or '\n",
            "                                     'iteration.\\n'\n",
            "                                     '\\n'\n",
            "                                     '1. Using recursion:\\n'\n",
            "                                     '```python\\n'\n",
            "                                     'def fibonacci(n):\\n'\n",
            "                                     '    if n <= 1:\\n'\n",
            "                                     '        return n\\n'\n",
            "                                     '    else:\\n'\n",
            "                                     '        return fibonacci(n-1) + '\n",
            "                                     'fibonacci(n-2)\\n'\n",
            "                                     '\\n'\n",
            "                                     'fibonacci_number = fibonacci(14)\\n'\n",
            "                                     'print(fibonacci_number)\\n'\n",
            "                                     '```\\n'\n",
            "                                     '\\n'\n",
            "                                     '2. Using iteration:\\n'\n",
            "                                     '```python\\n'\n",
            "                                     'def fibonacci(n):\\n'\n",
            "                                     '    if n <= 1:\\n'\n",
            "                                     '        return n\\n'\n",
            "                                     '    else:\\n'\n",
            "                                     '        a, b = 0, 1\\n'\n",
            "                                     '        for _ in range(n-1):\\n'\n",
            "                                     '            a, b = b, a + b\\n'\n",
            "                                     '        return b\\n'\n",
            "                                     '\\n'\n",
            "                                     'fibonacci_number = fibonacci(14)\\n'\n",
            "                                     'print(fibonacci_number)\\n'\n",
            "                                     '```\\n'\n",
            "                                     '\\n'\n",
            "                                     'Both approaches will give the same '\n",
            "                                     'result: the 14th Fibonacci number is '\n",
            "                                     '377.',\n",
            "                          'name': 'code_writer',\n",
            "                          'role': 'user'},\n",
            "                         {'content': 'exitcode: 0 (execution succeeded)\\n'\n",
            "                                     'Code output: 377\\n'\n",
            "                                     '377\\n',\n",
            "                          'name': 'coding_dog',\n",
            "                          'role': 'assistant'},\n",
            "                         {'content': 'Correct! The 14th Fibonacci number is '\n",
            "                                     'indeed 377.',\n",
            "                          'name': 'code_writer',\n",
            "                          'role': 'user'},\n",
            "                         {'content': '',\n",
            "                          'name': 'coding_dog',\n",
            "                          'role': 'assistant'}],\n",
            "           summary='',\n",
            "           cost={'usage_excluding_cached_inference': {'ft:gpt-3.5-turbo-0613:shinkisa::8VomhV43': {'completion_tokens': 181,\n",
            "                                                                                                   'cost': 0,\n",
            "                                                                                                   'prompt_tokens': 946,\n",
            "                                                                                                   'total_tokens': 1127},\n",
            "                                                      'total_cost': 0},\n",
            "                 'usage_including_cached_inference': {'ft:gpt-3.5-turbo-0613:shinkisa::8VomhV43': {'completion_tokens': 181,\n",
            "                                                                                                   'cost': 0,\n",
            "                                                                                                   'prompt_tokens': 946,\n",
            "                                                                                                   'total_tokens': 1127},\n",
            "                                                      'total_cost': 0}},\n",
            "           human_input=[])\n"
          ]
        }
      ]
    }
  ]
}