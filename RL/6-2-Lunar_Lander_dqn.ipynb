{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/AI-Innovation-2024/blob/main/RL/6-2-Lunar_Lander_dqn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "# Stable Baselines3 - Training, Saving and Loading\n",
        "\n",
        "Github Repo: [https://github.com/DLR-RM/stable-baselines3](https://github.com/DLR-RM/stable-baselines3)\n",
        "\n",
        "\n",
        "[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo) is a training framework for Reinforcement Learning (RL), using Stable Baselines3.\n",
        "\n",
        "It provides scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.\n",
        "\n",
        "Documentation is available online: [https://stable-baselines3.readthedocs.io/](https://stable-baselines3.readthedocs.io/)\n",
        "\n",
        "## Install Dependencies and Stable Baselines Using Pip\n",
        "\n",
        "\n",
        "```\n",
        "pip install stable-baselines3[extra]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i2ODQjxJM80e"
      },
      "outputs": [],
      "source": [
        "# for autoformatting\n",
        "# %load_ext jupyter_black"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWskDE2c9WoN"
      },
      "outputs": [],
      "source": [
        "!apt-get update && apt-get install swig cmake\n",
        "!pip install box2d-py\n",
        "!pip install \"stable-baselines3[extra]>=2.0.0a4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "## Import policy, RL agent, ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BIedd7Pz9sOs",
        "outputId": "ee6a5d18-f95b-4006-b153-9b3e8c721f96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/util.py:55: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n",
            "  from jax import xla_computation as _xla_computation\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "from stable_baselines3 import DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RapkYvTXL7Cd"
      },
      "source": [
        "## Create the Gym env and instantiate the agent\n",
        "\n",
        "For this example, we will use Lunar Lander environment.\n",
        "\n",
        "\"Landing outside landing pad is possible. Fuel is infinite, so an agent can learn to fly and then land on its first attempt. Four discrete actions available: do nothing, fire left orientation engine, fire main engine, fire right orientation engine. \"\n",
        "\n",
        "Lunar Lander environment: [https://gymnasium.farama.org/environments/box2d/lunar_lander/](https://gymnasium.farama.org/environments/box2d/lunar_lander/)\n",
        "\n",
        "![Lunar Lander](https://cdn-images-1.medium.com/max/960/1*f4VZPKOI0PYNWiwt0la0Rg.gif)\n",
        "\n",
        "\n",
        "We chose the MlpPolicy because input of Lunar Lander is a feature vector, not images.\n",
        "\n",
        "The type of action to use (discrete/continuous) will be automatically deduced from the environment action space\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pUWGZp3i9wyf",
        "outputId": "a65c0c30-b2da-4383-d11a-d7d7b82b3833",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'LunarLander-v2'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "model = DQN(\n",
        "    \"MlpPolicy\",\n",
        "    \"LunarLander-v2\",\n",
        "    verbose=1,\n",
        "    exploration_final_eps=0.1,\n",
        "    target_update_interval=250,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4efFdrQ7MBvl"
      },
      "source": [
        "We load a helper function to evaluate the agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PeaVBGuJwK97",
        "outputId": "6dceedb2-30f0-4d1e-b67c-6a58073e8834",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjEVOIY8NVeK"
      },
      "source": [
        "Let's evaluate the un-trained agent, this should be a random agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xDHLMA6NFk95",
        "outputId": "417faa98-9a4e-4464-de48-4ef6dcef9109",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward=-503.60 +/- 124.1597164443068\n"
          ]
        }
      ],
      "source": [
        "# Separate env for evaluation\n",
        "eval_env = gym.make(\"LunarLander-v2\")\n",
        "\n",
        "# Random Agent, before training\n",
        "mean_reward, std_reward = evaluate_policy(\n",
        "    model,\n",
        "    eval_env,\n",
        "    n_eval_episodes=10,\n",
        "    deterministic=True,\n",
        ")\n",
        "\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5UoXTZPNdFE"
      },
      "source": [
        "## Train the agent and save it\n",
        "\n",
        "Warning: this may take a while"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4cfSXIB-pTF",
        "outputId": "9148159f-8e49-484d-ac83-91af5609b763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 96       |\n",
            "|    ep_rew_mean      | -127     |\n",
            "|    exploration_rate | 0.965    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 390      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 384      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.92     |\n",
            "|    n_updates        | 70       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.6     |\n",
            "|    ep_rew_mean      | -141     |\n",
            "|    exploration_rate | 0.935    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 557      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 717      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.41     |\n",
            "|    n_updates        | 154      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 94.3     |\n",
            "|    ep_rew_mean      | -138     |\n",
            "|    exploration_rate | 0.898    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 674      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1132     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.93     |\n",
            "|    n_updates        | 257      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.5     |\n",
            "|    ep_rew_mean      | -127     |\n",
            "|    exploration_rate | 0.86     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 747      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1560     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.38     |\n",
            "|    n_updates        | 364      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 100      |\n",
            "|    ep_rew_mean      | -160     |\n",
            "|    exploration_rate | 0.82     |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 790      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 2004     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.983    |\n",
            "|    n_updates        | 475      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.5     |\n",
            "|    ep_rew_mean      | -161     |\n",
            "|    exploration_rate | 0.789    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 785      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 2340     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.811    |\n",
            "|    n_updates        | 559      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 101      |\n",
            "|    ep_rew_mean      | -161     |\n",
            "|    exploration_rate | 0.745    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 787      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2835     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.3      |\n",
            "|    n_updates        | 683      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 102      |\n",
            "|    ep_rew_mean      | -173     |\n",
            "|    exploration_rate | 0.707    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 778      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3255     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.688    |\n",
            "|    n_updates        | 788      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | -175     |\n",
            "|    exploration_rate | 0.66     |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 762      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3778     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.741    |\n",
            "|    n_updates        | 919      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 107      |\n",
            "|    ep_rew_mean      | -190     |\n",
            "|    exploration_rate | 0.615    |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 777      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4275     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.57     |\n",
            "|    n_updates        | 1043     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 114      |\n",
            "|    ep_rew_mean      | -199     |\n",
            "|    exploration_rate | 0.55     |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 785      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 5000     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.97     |\n",
            "|    n_updates        | 1224     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 117      |\n",
            "|    ep_rew_mean      | -194     |\n",
            "|    exploration_rate | 0.493    |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 793      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 5636     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.15     |\n",
            "|    n_updates        | 1383     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 127      |\n",
            "|    ep_rew_mean      | -194     |\n",
            "|    exploration_rate | 0.404    |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 781      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 6627     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.56     |\n",
            "|    n_updates        | 1631     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 133      |\n",
            "|    ep_rew_mean      | -197     |\n",
            "|    exploration_rate | 0.332    |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 761      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 7425     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.15     |\n",
            "|    n_updates        | 1831     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 140      |\n",
            "|    ep_rew_mean      | -192     |\n",
            "|    exploration_rate | 0.244    |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 759      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 8400     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.76     |\n",
            "|    n_updates        | 2074     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 147      |\n",
            "|    ep_rew_mean      | -197     |\n",
            "|    exploration_rate | 0.156    |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 753      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 9381     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.67     |\n",
            "|    n_updates        | 2320     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 164      |\n",
            "|    ep_rew_mean      | -203     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 686      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 11166    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.46     |\n",
            "|    n_updates        | 2766     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 163      |\n",
            "|    ep_rew_mean      | -210     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 678      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 11715    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.36     |\n",
            "|    n_updates        | 2903     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 169      |\n",
            "|    ep_rew_mean      | -215     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 657      |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 12862    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.81     |\n",
            "|    n_updates        | 3190     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 168      |\n",
            "|    ep_rew_mean      | -225     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 661      |\n",
            "|    time_elapsed     | 20       |\n",
            "|    total_timesteps  | 13477    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.4      |\n",
            "|    n_updates        | 3344     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 165      |\n",
            "|    ep_rew_mean      | -242     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 664      |\n",
            "|    time_elapsed     | 20       |\n",
            "|    total_timesteps  | 13837    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.36     |\n",
            "|    n_updates        | 3434     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 162      |\n",
            "|    ep_rew_mean      | -248     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 666      |\n",
            "|    time_elapsed     | 21       |\n",
            "|    total_timesteps  | 14238    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.08     |\n",
            "|    n_updates        | 3534     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 179      |\n",
            "|    ep_rew_mean      | -244     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 590      |\n",
            "|    time_elapsed     | 27       |\n",
            "|    total_timesteps  | 16463    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.87     |\n",
            "|    n_updates        | 4090     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 213      |\n",
            "|    ep_rew_mean      | -238     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 537      |\n",
            "|    time_elapsed     | 38       |\n",
            "|    total_timesteps  | 20463    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.966    |\n",
            "|    n_updates        | 5090     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 245      |\n",
            "|    ep_rew_mean      | -230     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 500      |\n",
            "|    time_elapsed     | 48       |\n",
            "|    total_timesteps  | 24463    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.75     |\n",
            "|    n_updates        | 6090     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 273      |\n",
            "|    ep_rew_mean      | -228     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 478      |\n",
            "|    time_elapsed     | 57       |\n",
            "|    total_timesteps  | 27669    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.3      |\n",
            "|    n_updates        | 6892     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 310      |\n",
            "|    ep_rew_mean      | -223     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 459      |\n",
            "|    time_elapsed     | 68       |\n",
            "|    total_timesteps  | 31669    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.727    |\n",
            "|    n_updates        | 7892     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 339      |\n",
            "|    ep_rew_mean      | -215     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 462      |\n",
            "|    time_elapsed     | 75       |\n",
            "|    total_timesteps  | 35009    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.977    |\n",
            "|    n_updates        | 8727     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 356      |\n",
            "|    ep_rew_mean      | -215     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 465      |\n",
            "|    time_elapsed     | 79       |\n",
            "|    total_timesteps  | 37152    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.817    |\n",
            "|    n_updates        | 9262     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 374      |\n",
            "|    ep_rew_mean      | -202     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 467      |\n",
            "|    time_elapsed     | 84       |\n",
            "|    total_timesteps  | 39390    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.846    |\n",
            "|    n_updates        | 9822     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 392      |\n",
            "|    ep_rew_mean      | -195     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 470      |\n",
            "|    time_elapsed     | 88       |\n",
            "|    total_timesteps  | 41559    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.958    |\n",
            "|    n_updates        | 10364    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 412      |\n",
            "|    ep_rew_mean      | -184     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 469      |\n",
            "|    time_elapsed     | 93       |\n",
            "|    total_timesteps  | 44023    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.431    |\n",
            "|    n_updates        | 10980    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 420      |\n",
            "|    ep_rew_mean      | -175     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 472      |\n",
            "|    time_elapsed     | 95       |\n",
            "|    total_timesteps  | 45220    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.805    |\n",
            "|    n_updates        | 11279    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 426      |\n",
            "|    ep_rew_mean      | -170     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 475      |\n",
            "|    time_elapsed     | 97       |\n",
            "|    total_timesteps  | 46405    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.72     |\n",
            "|    n_updates        | 11576    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 443      |\n",
            "|    ep_rew_mean      | -155     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 476      |\n",
            "|    time_elapsed     | 101      |\n",
            "|    total_timesteps  | 48539    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.78     |\n",
            "|    n_updates        | 12109    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 448      |\n",
            "|    ep_rew_mean      | -143     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 479      |\n",
            "|    time_elapsed     | 103      |\n",
            "|    total_timesteps  | 49840    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.9      |\n",
            "|    n_updates        | 12434    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 455      |\n",
            "|    ep_rew_mean      | -138     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 480      |\n",
            "|    time_elapsed     | 106      |\n",
            "|    total_timesteps  | 51088    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.781    |\n",
            "|    n_updates        | 12746    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 455      |\n",
            "|    ep_rew_mean      | -133     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 482      |\n",
            "|    time_elapsed     | 107      |\n",
            "|    total_timesteps  | 52140    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.746    |\n",
            "|    n_updates        | 13009    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 457      |\n",
            "|    ep_rew_mean      | -127     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 485      |\n",
            "|    time_elapsed     | 109      |\n",
            "|    total_timesteps  | 53096    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.43     |\n",
            "|    n_updates        | 13248    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 458      |\n",
            "|    ep_rew_mean      | -124     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 488      |\n",
            "|    time_elapsed     | 110      |\n",
            "|    total_timesteps  | 54176    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.629    |\n",
            "|    n_updates        | 13518    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 458      |\n",
            "|    ep_rew_mean      | -116     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 491      |\n",
            "|    time_elapsed     | 112      |\n",
            "|    total_timesteps  | 55224    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.844    |\n",
            "|    n_updates        | 13780    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 449      |\n",
            "|    ep_rew_mean      | -107     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 493      |\n",
            "|    time_elapsed     | 113      |\n",
            "|    total_timesteps  | 56110    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.574    |\n",
            "|    n_updates        | 14002    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 455      |\n",
            "|    ep_rew_mean      | -95.1    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 496      |\n",
            "|    time_elapsed     | 115      |\n",
            "|    total_timesteps  | 57212    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.595    |\n",
            "|    n_updates        | 14277    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 455      |\n",
            "|    ep_rew_mean      | -85.5    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 499      |\n",
            "|    time_elapsed     | 116      |\n",
            "|    total_timesteps  | 58316    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.763    |\n",
            "|    n_updates        | 14553    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 462      |\n",
            "|    ep_rew_mean      | -69.2    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 498      |\n",
            "|    time_elapsed     | 119      |\n",
            "|    total_timesteps  | 59641    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 6.09     |\n",
            "|    n_updates        | 14885    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 483      |\n",
            "|    ep_rew_mean      | -45.2    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 498      |\n",
            "|    time_elapsed     | 124      |\n",
            "|    total_timesteps  | 62154    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.808    |\n",
            "|    n_updates        | 15513    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 492      |\n",
            "|    ep_rew_mean      | -34.7    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 500      |\n",
            "|    time_elapsed     | 126      |\n",
            "|    total_timesteps  | 63388    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.887    |\n",
            "|    n_updates        | 15821    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 485      |\n",
            "|    ep_rew_mean      | -25.1    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 502      |\n",
            "|    time_elapsed     | 129      |\n",
            "|    total_timesteps  | 65009    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.804    |\n",
            "|    n_updates        | 16227    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 464      |\n",
            "|    ep_rew_mean      | -21.7    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 501      |\n",
            "|    time_elapsed     | 133      |\n",
            "|    total_timesteps  | 66881    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.92     |\n",
            "|    n_updates        | 16695    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 442      |\n",
            "|    ep_rew_mean      | -23.4    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 504      |\n",
            "|    time_elapsed     | 136      |\n",
            "|    total_timesteps  | 68624    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.11     |\n",
            "|    n_updates        | 17130    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 427      |\n",
            "|    ep_rew_mean      | -21.8    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 506      |\n",
            "|    time_elapsed     | 139      |\n",
            "|    total_timesteps  | 70401    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.529    |\n",
            "|    n_updates        | 17575    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 401      |\n",
            "|    ep_rew_mean      | -24.3    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 507      |\n",
            "|    time_elapsed     | 141      |\n",
            "|    total_timesteps  | 71756    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.16     |\n",
            "|    n_updates        | 17913    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 391      |\n",
            "|    ep_rew_mean      | -29.6    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 505      |\n",
            "|    time_elapsed     | 146      |\n",
            "|    total_timesteps  | 74087    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.29     |\n",
            "|    n_updates        | 18496    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 391      |\n",
            "|    ep_rew_mean      | -32.8    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 506      |\n",
            "|    time_elapsed     | 150      |\n",
            "|    total_timesteps  | 76252    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.512    |\n",
            "|    n_updates        | 19037    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 397      |\n",
            "|    ep_rew_mean      | -36.2    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 505      |\n",
            "|    time_elapsed     | 156      |\n",
            "|    total_timesteps  | 79067    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.943    |\n",
            "|    n_updates        | 19741    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 402      |\n",
            "|    ep_rew_mean      | -41.1    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 504      |\n",
            "|    time_elapsed     | 162      |\n",
            "|    total_timesteps  | 81795    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.617    |\n",
            "|    n_updates        | 20423    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 407      |\n",
            "|    ep_rew_mean      | -53.5    |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 504      |\n",
            "|    time_elapsed     | 167      |\n",
            "|    total_timesteps  | 84739    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.54     |\n",
            "|    n_updates        | 21159    |\n",
            "----------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Train the agent\n",
        "model.learn(total_timesteps=int(1e5))\n",
        "# Save the agent\n",
        "model.save(\"dqn_lunar\")\n",
        "del model  # delete trained model to demonstrate loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T31dZJYNrJwF"
      },
      "source": [
        "## Load the trained agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1ExgtyZrIA6"
      },
      "outputs": [],
      "source": [
        "model = DQN.load(\"dqn_lunar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygl_gVmV_QP7"
      },
      "outputs": [],
      "source": [
        "# Evaluate the trained agent\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
        "\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQDZI5VEGnUq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "saving_loading_dqn.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "3201c96db5836b171d01fee72ea1be894646622d4b41771abf25c98b548a611d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}