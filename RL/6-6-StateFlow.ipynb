{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/AI-Innovation-2024/blob/main/RL/6-6-StateFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install autogen"
      ],
      "metadata": {
        "id": "iP8G1At09aHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import openai\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "openai.api_key  = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "N9F3yYKgh8d_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CFBZCXrE9GX7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "\n",
        "from autogen.coding import LocalCommandLineCodeExecutor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXT5M0Vpha7l",
        "outputId": "21d6278a-193b-4c96-8e2f-514e16135b28"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dir = tempfile.TemporaryDirectory()\n",
        "executor = LocalCommandLineCodeExecutor(\n",
        "    timeout=1200,  # Timeout for each code execution in seconds.\n",
        "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
        ")\n",
        "\n",
        "gpt4_config = {\n",
        "    \"cache_seed\": False,  # change the cache_seed for different trials\n",
        "    \"temperature\": 0,\n",
        "    \"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}],\n",
        "    \"timeout\": 1200,\n",
        "}"
      ],
      "metadata": {
        "id": "rZo2T4O7gVCa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import autogen\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "#첫 대화를 실행하는 에이전트\n",
        "initializer = autogen.UserProxyAgent(\n",
        "    name=\"Init\",\n",
        "    code_execution_config=False,\n",
        "    human_input_mode=\"NEVER\"\n",
        ")\n",
        "\n",
        "# 첫 번째 코드 실행기 에이전트\n",
        "executor1 = autogen.UserProxyAgent(\n",
        "    name=\"Executor1\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    code_execution_config={\"executor\": executor},\n",
        ")\n",
        "\n",
        "# 두 번째 코드 실행기 에이전트\n",
        "executor2 = autogen.UserProxyAgent(\n",
        "    name=\"Executor2\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    code_execution_config={\"executor\": executor},\n",
        ")\n",
        "\n",
        "# GPT 모델을 사용하는 감시 에이전트\n",
        "monitor = autogen.AssistantAgent(\n",
        "    name=\"Monitor\",\n",
        "    llm_config=gpt4_config,\n",
        "    system_message=\"당신은 코드 실행을 감시하고 결과를 보고하는 모니터입니다. 각 실행기의 결과를 분석하고 요약하여 보고해주세요.\"\n",
        ")\n",
        "def state_transition(last_speaker, groupchat):\n",
        "    if last_speaker == initializer:\n",
        "        return executor1\n",
        "    elif last_speaker == executor1:\n",
        "        return executor2\n",
        "    elif last_speaker == executor2:\n",
        "        return monitor\n",
        "    elif last_speaker == monitor:\n",
        "        return None  # 모니터 이후에 대화 종료\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# 그룹 채팅 매니저 설정\n",
        "groupchat = autogen.GroupChat(agents=[initializer, executor1, executor2, monitor], messages=[], max_round=10, speaker_selection_method=state_transition)\n",
        "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=gpt4_config)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G2kP8SithCS7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드 블록 정의\n",
        "code_block = \"\"\"\n",
        "print(f\"테스트\")\n",
        "\"\"\"\n",
        "# initializer가 채팅 시작\n",
        "initializer.initiate_chat(\n",
        "    manager,\n",
        "    message=f\"코드 실행 테스트를 시작합니다. Executor1과 Executor2가 순차적으로 다음 코드를 실행하고, Monitor가 결과를 분석할 것입니다. \\n코드실행기는 다음 코드를 실행하세요.:\\n```python\\n{code_block}\\n```\"\n",
        ")\n",
        "\n",
        "# Executor1에게 코드 실행 요청\n",
        "executor1.send(\n",
        "    message=f\"다음 코드를 실행하고 결과를 보고해주세요:\\n```python\\n{code_block}\\n```\",\n",
        "    recipient=manager\n",
        ")\n",
        "\n",
        "# Executor2에게 코드 실행 요청\n",
        "executor2.send(\n",
        "    message=f\"다음 코드를 실행하고 결과를 보고해주세요:\\n```python\\n{code_block}\\n```\",\n",
        "    recipient=manager\n",
        ")\n",
        "\n",
        "# Monitor에게 결과 분석 요청\n",
        "monitor.send(\n",
        "    message=\"Executor1과 Executor2의 코드 실행 결과를 분석하고 보고해주세요.\",\n",
        "    recipient=manager\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26S2qfzdifRm",
        "outputId": "a09fb37e-ff75-4824-fd33-53c01c1a89e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init (to chat_manager):\n",
            "\n",
            "코드 실행 테스트를 시작합니다. Executor1과 Executor2가 순차적으로 다음 코드를 실행하고, Monitor가 결과를 분석할 것입니다. \n",
            "코드실행기는 다음 코드를 실행하세요.:\n",
            "```python\n",
            "\n",
            "print(f\"테스트\")\n",
            "\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: Executor1\n",
            "\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\n",
            "Executor1 (to chat_manager):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: 테스트\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: Executor2\n",
            "\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\n",
            "Executor2 (to chat_manager):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: 테스트\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: Monitor\n",
            "\n",
            "Monitor (to chat_manager):\n",
            "\n",
            "모든 실행기가 코드를 성공적으로 실행했습니다. 코드의 출력은 \"테스트\"입니다. 에러나 예외는 발생하지 않았습니다.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Executor1 (to chat_manager):\n",
            "\n",
            "다음 코드를 실행하고 결과를 보고해주세요:\n",
            "```python\n",
            "\n",
            "print(f\"테스트\")\n",
            "\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Executor2 (to chat_manager):\n",
            "\n",
            "다음 코드를 실행하고 결과를 보고해주세요:\n",
            "```python\n",
            "\n",
            "print(f\"테스트\")\n",
            "\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Monitor (to chat_manager):\n",
            "\n",
            "Executor1과 Executor2의 코드 실행 결과를 분석하고 보고해주세요.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Executor1에게 코드 실행 요청\n",
        "# executor1.send(\n",
        "#     f\"다음 코드를 실행해주세요:\\n```python\\n{code_block}\\n```\",\n",
        "#     manager\n",
        "# )\n",
        "\n",
        "# # Executor2에게 코드 실행 요청\n",
        "# executor2.send(\n",
        "#     f\"Executor1의 실행 결과를 확인하고, 다음 코드를 실행해주세요:\\n```python\\n{code_block}\\n```\",\n",
        "#     manager\n",
        "# )\n",
        "\n",
        "# # 모니터에게 결과 분석 요청\n",
        "# monitor.send(\n",
        "#     \"두 실행기의 코드 실행 결과를 분석하고 보고해주세요.\",\n",
        "#     manager\n",
        "# )"
      ],
      "metadata": {
        "id": "JDiST_J6lEQJ"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}