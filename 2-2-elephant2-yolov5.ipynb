{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlgWwgh5XpIQEbvrc0Ud/K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/AI-Innovation-2024/blob/main/2-2-elephant2-yolov5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV_HxZEK8AtU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Load the YOLOv5 model (you might need to adjust the model path or use a pretrained one from PyTorch Hub)\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # Use 'yolov5s' for a small model, or 'yolov5x' for a large one\n",
        "\n",
        "# Load the image\n",
        "img_path = './elephant2.png'\n",
        "img = Image.open(img_path)\n",
        "\n",
        "# Perform inference\n",
        "results = model(img)\n",
        "\n",
        "# Extract the bounding boxes and confidence scores\n",
        "detections = results.xyxy[0].numpy()\n",
        "\n",
        "# Filter out detections based on the class (16 for elephants in COCO dataset)\n",
        "elephant_class_id = 16  # Adjust based on the specific model's class ID for elephants\n",
        "elephant_detections = detections[detections[:, 5] == elephant_class_id]\n",
        "\n",
        "# Save the bounding box coordinates (x1, y1, x2, y2) to a NumPy array\n",
        "bounding_boxes = elephant_detections[:, :4]\n",
        "\n",
        "# Save the numpy array to a file\n",
        "np.save('./elephant_bounding_boxes.npy', bounding_boxes)\n",
        "\n",
        "print(\"Bounding box coordinates saved:\", bounding_boxes)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "\n",
        "# Load the image\n",
        "img_path = 'elephant2.png'  # Adjust this if you named the file differently after uploading\n",
        "img = Image.open(img_path)\n",
        "\n",
        "# Load the bounding boxes\n",
        "bounding_boxes = np.load('elephant_bounding_boxes.npy')\n",
        "\n",
        "# Display the image\n",
        "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
        "ax.imshow(img)\n",
        "\n",
        "# Draw the bounding boxes\n",
        "for box in bounding_boxes:\n",
        "    x1, y1, x2, y2 = box\n",
        "    width = x2 - x1\n",
        "    height = y2 - y1\n",
        "    rect = patches.Rectangle((x1, y1), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7jROmmgD9qhv"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}