{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVKjFvEH2VXF7BH26++8yg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/AI-Innovation-2024/blob/main/OpenCV/3-9-CLIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxWRck38y0Wn"
      },
      "outputs": [],
      "source": [
        "!pip install inference inference[clip]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "export ROBOFLOW_API_KEY=\"\""
      ],
      "metadata": {
        "id": "73XNYK0bz0R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import userdata\n",
        "# userdata.get('ROBOFLOW_API_KEY')"
      ],
      "metadata": {
        "id": "jqc_8nmpy_N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "gH7uhFCfzP4j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import inference\n",
        "from inference.core.utils.postprocess import cosine_similarity\n",
        "\n",
        "from inference.models import Clip\n",
        "clip = Clip()\n",
        "\n",
        "prompt = \"a coffee cup\"\n",
        "text_embedding = clip.embed_text(prompt)\n",
        "\n",
        "def render(result, image):\n",
        "    # get the cosine similarity between the prompt & the image\n",
        "    similarity = cosine_similarity(result[\"embeddings\"][0], text_embedding[0])\n",
        "\n",
        "    # scale the result to 0-100 based on heuristic (~the best & worst values I've observed)\n",
        "    range = (0.15, 0.40)\n",
        "    similarity = (similarity-range[0])/(range[1]-range[0])\n",
        "    similarity = max(min(similarity, 1), 0)*100\n",
        "\n",
        "    # print the similarity\n",
        "    text = f\"{similarity:.1f}%\"\n",
        "    cv2.putText(image, text, (10, 310), cv2.FONT_HERSHEY_SIMPLEX, 12, (255, 255, 255), 30)\n",
        "    cv2.putText(image, text, (10, 310), cv2.FONT_HERSHEY_SIMPLEX, 12, (206, 6, 103), 16)\n",
        "\n",
        "    # print the prompt\n",
        "    cv2.putText(image, prompt, (20, 1050), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 10)\n",
        "    cv2.putText(image, prompt, (20, 1050), cv2.FONT_HERSHEY_SIMPLEX, 2, (206, 6, 103), 5)\n",
        "\n",
        "    # display the image\n",
        "    cv2.imshow(\"CLIP\", image)\n",
        "    # cv2_imshow(image)\n",
        "    cv2.waitKey(1)\n",
        "\n",
        "# start the stream\n",
        "inference.Stream(\n",
        "    source=\"webcam\",\n",
        "    model=clip,\n",
        "\n",
        "    output_channel_order=\"BGR\",\n",
        "    use_main_thread=True,\n",
        "\n",
        "    on_prediction=render\n",
        ")"
      ],
      "metadata": {
        "id": "UW_Sp-DRzHfY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}